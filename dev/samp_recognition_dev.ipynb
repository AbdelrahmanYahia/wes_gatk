{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys\n",
    "import yaml \n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "now = datetime.datetime.now()\n",
    "start_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "import os\n",
    "os.environ['start_time'] = start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class RunTime:\n",
    "    def __init__(self, start_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")):\n",
    "        self.start_time = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def elapsed(self):\n",
    "        self.end_time = datetime.now()\n",
    "        return f'Duration: {self.end_time - self.start_time}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols\n",
    "RED = \"\\033[;31;1m\"\n",
    "RED_ = \"\\033[;31;4m\"\n",
    "GRE = \"\\033[;32;1m\"\n",
    "YEL = \"\\033[;33;1m\"\n",
    "BLU = \"\\033[;34;1m\"\n",
    "PRP = \"\\033[;35;1m\"\n",
    "CYN = \"\\033[;36;1m\"\n",
    "BLD = \"\\033[;37;1m\"\n",
    "GRY = \"\\033[;30;1m\"\n",
    "NC = \"\\033[;39;0m\"\n",
    "NC_ = \"\\033[;39;4m\"\n",
    "\n",
    "start_time = os.environ['start_time']\n",
    "runtime = RunTime(start_time)\n",
    "\n",
    "\n",
    "\n",
    "# other vars\n",
    "global_vars = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFormatter(logging.Formatter):\n",
    "    ### code from:\n",
    "    ## https://stackoverflow.com/questions/384076/how-can-i-color-python-logging-output\n",
    "\n",
    "    format = \"[%(asctime)s] %(levelname)s: %(message)s\"\n",
    "    datefmtstr = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    FORMATS = {\n",
    "        logging.DEBUG: format.replace('%(levelname)s', GRY + '%(levelname)s' + NC),\n",
    "        logging.INFO: format.replace('%(levelname)s', GRY + '%(levelname)s' + NC),\n",
    "        logging.WARNING: format.replace('%(levelname)s', YEL + '%(levelname)s' + NC),\n",
    "        logging.ERROR: format.replace('%(levelname)s', RED + '%(levelname)s' + NC),\n",
    "        logging.CRITICAL: format.replace('%(levelname)s', RED_ + '%(levelname)s' + NC),\n",
    "    }\n",
    "\n",
    "    def format(self, record):\n",
    "        log_fmt = self.FORMATS.get(record.levelno)\n",
    "        formatter = logging.Formatter(log_fmt, datefmt=self.datefmtstr)\n",
    "        return formatter.format(record)\n",
    "    \n",
    "\n",
    "class GLogger:\n",
    "    def __init__(self):\n",
    "        # create logger attr and set level\n",
    "        self.logger = logging.getLogger('GUAP_logger')\n",
    "        self.formatter = logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def create_console_handler(self, verbose=False):\n",
    "        # create handler\n",
    "        self.ch = logging.StreamHandler()\n",
    "\n",
    "        # set level according to user verbose option\n",
    "        if verbose:\n",
    "            self.ch.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            self.ch.setLevel(logging.WARNING)\n",
    "\n",
    "        self.ch.setFormatter(CustomFormatter())\n",
    "\n",
    "        # add handler\n",
    "        self.logger.addHandler(self.ch)\n",
    "\n",
    "    def create_file_handler(self, file):\n",
    "        # create handler\n",
    "        self.fh = logging.FileHandler(file)\n",
    "        self.fh.setLevel(logging.DEBUG)\n",
    "        self.fh.setFormatter(self.formatter)\n",
    "\n",
    "        self.logger.addHandler(self.fh)\n",
    "\n",
    "\n",
    "    def prnt_info(self, str):\n",
    "        self.logger.info(f\"{str}\")\n",
    "\n",
    "\n",
    "    def prnt_warning(self, str):\n",
    "        self.logger.warning(f\"{str}\")\n",
    "\n",
    "\n",
    "    def prnt_error(self, str):\n",
    "        self.logger.error(f\"{str}\")\n",
    "\n",
    "\n",
    "    def prnt_fatel(self, str):\n",
    "        self.logger.fatal(f\"{str}\")\n",
    "        print(f\"{PRP}{runtime.elapsed()}{NC}\")\n",
    "        exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glogger = GLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_extension(df): # takes pandas df and returns string\n",
    "    # checks all files have same extension from pandas df, to use in generete sample table function\n",
    "    uniques = df['ext'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        glogger.prnt_fatel(f\"Your input directory has multible fastq file extensions, please check directory.\")\n",
    "\n",
    "    else:\n",
    "        return uniques[0]\n",
    "\n",
    "\n",
    "def check_PE(df): # takes pandas df and returns string\n",
    "    \"\"\"checks all files either single or paried ended from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['PE'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        glogger.prnt_fatel(f\"Your input directory has both Paired and single files, please check directory.\")\n",
    "    else:\n",
    "        return uniques[0]\n",
    "\n",
    "\n",
    "def check_R(df): # takes pandas df and returns string\n",
    "    \"\"\"checks all files have same naming patterns from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['read_num'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        glogger.prnt_fatel(f\"Your input directory has multible fastq file naming patterns, please check directory.\")\n",
    "    else:\n",
    "        return uniques[0].replace(\"1\",\"\")\n",
    "\n",
    "\n",
    "def check_pattern(df): # takes pandas df and returns a string \n",
    "    \"\"\"checks all files have same naming patterns from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['matched_pattern'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        glogger.prnt_fatel(f\"Your input directory has multible fastq file naming patterns, please check directory.\")\n",
    "    else:\n",
    "        return uniques[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recogize_pattern(file_name): # takes string of fastq file name and returns dict with read info and id\n",
    "    \"\"\" using re to recognize the naming pattern of samples (illumina, srr and general naming patten)\"\"\"\n",
    "    # naming pattern for re \n",
    "    patterns = { # ! fix (_|\\.) group for R pattern in dict config !\n",
    "        \"Novagen1\": \"(((.+)_(.+)-(.+))_(L\\d+)((_)([1|2]))\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"Novagen2\": \"(((.+)_(.+)-(.+))_(L\\d+)((-)(r[1|2]))\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"illumina\": \"(((.+)_(S\\d+)_(L00\\d))_(R1|R2|r1|r2|read1|read2)_(00\\d)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"SRR\": \"(((SRR)(\\d+))(_|\\.)(1|2|R1|R2|r1|r2|read1|read2)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"general\": \"(((.+))(_|\\.)(1|2|R1|R2|r1|r2|read1|read2)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\"\n",
    "    }\n",
    "\n",
    "    matched_pattern = None\n",
    "    ## loop on pattern to and checks whichs one matches \n",
    "    ## starting with illumina because general would match any ways\n",
    "    ## breaks once successful \n",
    "    for ptrn_name, pattern in patterns.items():\n",
    "        try:\n",
    "            matched = re.match(pattern, file_name) \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if bool(matched) :\n",
    "            matched_pattern = ptrn_name\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if matched_pattern == \"Novagen1\":\n",
    "        file_name, sample_name, sample_id, acc1, acc2, lane, R_pattern, R_sep, read_num, ext, tail, sample_number =  matched.groups()[0], matched.groups()[1], matched.groups()[2], matched.groups()[3], matched.groups()[4], matched.groups()[5], matched.groups()[6], matched.groups()[7] , matched.groups()[8] , matched.groups()[9], \"\", \"\"\n",
    "\n",
    "    elif matched_pattern == \"Novagen2\":\n",
    "        file_name, sample_name, sample_id, acc1, acc2, lane, R_pattern, R_sep, read_num, ext, tail, sample_number =  matched.groups()[0], matched.groups()[1], matched.groups()[2], matched.groups()[3], matched.groups()[4], matched.groups()[5], matched.groups()[6], matched.groups()[7] , matched.groups()[8] , matched.groups()[9], \"\", \"\"\n",
    "\n",
    "    elif matched_pattern == \"illumina\":\n",
    "        file_name, sample_name, sample_id, sample_number, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[2], matched.groups()[3], matched.groups()[5], matched.groups()[4], matched.groups()[6], matched.groups()[7]\n",
    "\n",
    "    elif matched_pattern == \"SRR\":\n",
    "        glogger.prnt_fatel(f\"{RED}{matched_pattern}{NC} is currntly not supported sample naming pattern\\nonly {GRE}'Illumina'{NC} naming pattern is supported at the moment\")\n",
    "        file_name, sample_name, sample_id, sample_number, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[3], \"\", matched.groups()[5], \"\", \"\", matched.groups()[6]\n",
    "\n",
    "    elif matched_pattern == \"general\":\n",
    "        glogger.prnt_fatel(f\"{RED}{matched_pattern}{NC} is currntly not supported sample naming pattern\\nonly {GRE}'Illumina'{NC} naming pattern is supported at the moment\")\n",
    "        file_name, sample_name, sample_id, sample_number, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[1], \"\", matched.groups()[4], \"\", \"\", matched.groups()[5]\n",
    "\n",
    "    else:\n",
    "        glogger.prnt_fatel(f\"{RED}Your Samples Pattern is an unfamiler pattern.{NC}\\nPlease contact my Developpers and they will look into it :D\")\n",
    "        file_name = sample_name = sample_id = sample_number = read_num = lane = tail = ext = None\n",
    "\n",
    "\n",
    "    if matched_pattern == \"Novagen1\" or matched_pattern == \"Novagen2\":\n",
    "        return {\n",
    "            \"file_name\": file_name,\n",
    "            \"sample_name\": sample_name,\n",
    "            \"sample_id\": sample_id,\n",
    "            \"acc1\": acc1,\n",
    "            \"acc2\": acc2,\n",
    "            \"lane\": lane,\n",
    "            \"R_pattern\" : R_pattern, \n",
    "            \"R_sep\" : R_sep, \n",
    "            \"read_num\" : read_num, \n",
    "            \"ext\" : ext,\n",
    "            \"tail\": tail,\n",
    "            \"sample_number\": sample_number,\n",
    "            \"matched_pattern\": ptrn_name\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # Returns a dictionary of sample information\n",
    "        return {\n",
    "            \"file_name\": file_name,\n",
    "            \"sample_name\": sample_name,\n",
    "            \"sample_id\": sample_id,\n",
    "            \"sample_number\": sample_number,\n",
    "            \"read_num\": read_num,\n",
    "            \"lane\": lane,\n",
    "            \"tail\": tail,\n",
    "            \"ext\": ext,\n",
    "            \"matched_pattern\": ptrn_name\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_samples(inpath): # takes path return contains fastq files, returns df contains sample information\n",
    "    ## takes input path\n",
    "    ## gets the file names containg fastq and fq\n",
    "    ## performs the recogize_pattern function to \n",
    "    ## capture sample information and stores it in \n",
    "    ## pandas df\n",
    "    # input path to absolute path\n",
    "    path = os.path.abspath(inpath)\n",
    "    # list all files\n",
    "    all_files = os.listdir(path)\n",
    "    samples = defaultdict(dict)\n",
    "    # takes fastq files only\n",
    "    for file_name in all_files:\n",
    "        if os.path.isfile(path + \"/\" + file_name) and (\"fastq\" in file_name or \"fq\" in file_name):\n",
    "            # Captures the file path and name\n",
    "            filename, file_extension = os.path.splitext(file_name)\n",
    "            if \"fastq\" in filename or \"fq\" in filename:\n",
    "                filename, new_ext = os.path.splitext(filename)\n",
    "                file_extension = new_ext + file_extension\n",
    "            # recogize_pattern function returns a dictitionary with sample names, id, and read information\n",
    "            sample_info = recogize_pattern(file_name)\n",
    "\n",
    "            # get only forward reads and replace the read number to get R2\n",
    "            # appends sample information to a dict of dicts\n",
    "            \n",
    "            if \"1\" in sample_info[\"read_num\"]:\n",
    "                read_2 = sample_info[\"read_num\"].replace(\"1\",\"2\")\n",
    "                if sample_info[\"matched_pattern\"] == \"illumina\":\n",
    "                    read_1 = f\"{sample_info['read_num']}_{sample_info['tail']}.f\"\n",
    "                    read_2 = f\"{read_2}_{sample_info['tail']}.f\"\n",
    "                else:\n",
    "                    read_1 = f\"{sample_info['read_num']}.f\"\n",
    "                    read_2 = f\"{read_2}.f\"\n",
    "\n",
    "                f2 = file_name.replace(read_1, read_2)\n",
    "                if f2 in all_files:\n",
    "                    sample_info[\"file2\"] = f2\n",
    "                    sample_info[\"PE\"] = True\n",
    "                    samples[sample_info[\"sample_id\"]] = sample_info\n",
    "\n",
    "                else:\n",
    "                    sample_info[\"file2\"] = \"\"\n",
    "                    sample_info[\"PE\"] = False\n",
    "\n",
    "    # converts the dict to pandas df and returns the df\n",
    "    m_samples = samples\n",
    "    samples= pd.DataFrame(samples).T\n",
    "    samples = samples.sort_values(by=['sample_id'])\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = parse_samples(\"empty_sample_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv(\"samples.tsv\",sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
